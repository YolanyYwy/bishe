"""
AI Agentæ ¸å¿ƒæ¡†æ¶
ä½¿ç”¨è½»é‡çº§å¤§æ¨¡å‹åè°ƒä¼ ç»ŸMLæ¨¡å‹å®Œæˆé¢„æµ‹ä»»åŠ¡
"""
import yaml
import os
import logging
from typing import Dict, Any, Optional
import pandas as pd
from grinding_speed_agent.llm import LocalLLM
from grinding_speed_agent.models import MLModelManager
from grinding_speed_agent.utils import DataProcessor, ReportGenerator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GrindingSpeedAgent:
    """ç ”ç£¨é€Ÿåº¦é¢„æµ‹Agent"""

    def __init__(self, config_path: str = "config/config.yaml"):
        """
        åˆå§‹åŒ–Agent

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        logger.info("Initializing Grinding Speed Agent...")

        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

        # åˆå§‹åŒ–ç»„ä»¶
        self.llm = None
        self.ml_manager = MLModelManager(self.config['ml_models'])
        self.data_processor = DataProcessor()
        self.report_generator = ReportGenerator(self.config['report']['output_dir'])

        # çŠ¶æ€
        self.conversation_history = []
        self.current_data = None
        self.model_results = None
        self.feature_importance = None

        logger.info("Agent initialized successfully!")

    def initialize_llm(self):
        """åˆå§‹åŒ–å¤§æ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼ŒèŠ‚çœèµ„æºï¼‰"""
        if self.llm is None:
            logger.info("Initializing LLM...")
            llm_config = self.config['llm']
            self.llm = LocalLLM(
                model_name=llm_config['model_name'],
                device=llm_config['device'],
                max_length=llm_config['max_length'],
                temperature=llm_config['temperature'],
                top_p=llm_config['top_p'],
                quantization_config=llm_config.get('quantization')
            )
            logger.info("LLM initialized!")

    def process_instruction(self, instruction: str, data_path: Optional[str] = None) -> str:
        """
        å¤„ç†ç”¨æˆ·æŒ‡ä»¤

        Args:
            instruction: ç”¨æˆ·æŒ‡ä»¤
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰

        Returns:
            å¤„ç†ç»“æœæè¿°
        """
        logger.info(f"Processing instruction: {instruction}")

        # è§£ææŒ‡ä»¤æ„å›¾
        intent = self._parse_intent(instruction)

        # æ ¹æ®æ„å›¾æ‰§è¡Œä¸åŒçš„ä»»åŠ¡
        if intent == 'train':
            return self._handle_training(instruction, data_path)
        elif intent == 'predict':
            return self._handle_prediction(instruction, data_path)
        elif intent == 'analyze':
            return self._handle_analysis(instruction, data_path)
        elif intent == 'report':
            return self._handle_report_generation(instruction)
        else:
            return self._handle_general_query(instruction)

    def _parse_intent(self, instruction: str) -> str:
        """
        è§£æç”¨æˆ·æ„å›¾

        Args:
            instruction: ç”¨æˆ·æŒ‡ä»¤

        Returns:
            æ„å›¾ç±»å‹
        """
        instruction_lower = instruction.lower()

        # å…³é”®è¯åŒ¹é…
        if any(kw in instruction_lower for kw in ['è®­ç»ƒ', 'train', 'å»ºæ¨¡', 'æ¨¡å‹']):
            return 'train'
        elif any(kw in instruction_lower for kw in ['é¢„æµ‹', 'predict', 'æ¨ç†', 'inference']):
            return 'predict'
        elif any(kw in instruction_lower for kw in ['åˆ†æ', 'analyze', 'æ•°æ®', 'data']):
            return 'analyze'
        elif any(kw in instruction_lower for kw in ['æŠ¥å‘Š', 'report', 'ç”ŸæˆæŠ¥å‘Š']):
            return 'report'
        else:
            return 'general'

    def _handle_training(self, instruction: str, data_path: str) -> str:
        """å¤„ç†è®­ç»ƒä»»åŠ¡"""
        logger.info("Handling training task...")

        try:
            # 1. åŠ è½½æ•°æ®
            df = self.data_processor.load_data(data_path)
            logger.info(f"Loaded data: {df.shape}")

            # 2. æ•°æ®é¢„å¤„ç†
            df = self.data_processor.preprocess_data(
                df,
                handle_missing='mean',
                remove_outliers=False
            )

            # 3. åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
            X, y = self.data_processor.split_features_target(df)

            # 4. ç‰¹å¾å·¥ç¨‹ï¼ˆå¯é€‰ï¼‰
            if self.config['data']['feature_engineering']['enabled']:
                X = self.data_processor.engineer_features(
                    X,
                    polynomial=self.config['data']['feature_engineering']['polynomial_features'],
                    interactions=self.config['data']['feature_engineering']['interaction_features']
                )

            # 5. è®­ç»ƒæ¨¡å‹
            self.model_results = self.ml_manager.train_models(
                X, y,
                test_size=self.config['data']['test_size'],
                random_state=self.config['data']['random_state']
            )

            # 6. è·å–ç‰¹å¾é‡è¦æ€§
            self.feature_importance = self.ml_manager.get_feature_importance()

            # 7. ä¿å­˜æ¨¡å‹
            self.ml_manager.save_models('grinding_speed_agent/models_saved')

            # 8. ä¿å­˜å½“å‰æ•°æ®
            self.current_data = df

            result = f"""
è®­ç»ƒå®Œæˆï¼

æœ€ä½³æ¨¡å‹: {self.model_results['best_model']}
æµ‹è¯•é›† RÂ²: {self.model_results['results'][self.model_results['best_model']]['test_metrics']['r2']:.4f}
è®­ç»ƒæ•°æ®: {len(df)} æ¡è®°å½•

æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜è‡³ models_saved/ ç›®å½•ã€‚
"""
            return result.strip()

        except Exception as e:
            logger.error(f"Training failed: {str(e)}")
            return f"è®­ç»ƒå¤±è´¥: {str(e)}"

    def _handle_prediction(self, instruction: str, data_path: str) -> str:
        """å¤„ç†é¢„æµ‹ä»»åŠ¡"""
        logger.info("Handling prediction task...")

        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ
            if not self.ml_manager.best_model:
                # å°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
                if os.path.exists('grinding_speed_agent/models_saved/metadata.pkl'):
                    self.ml_manager.load_models('grinding_speed_agent/models_saved')
                else:
                    return "é”™è¯¯ï¼šè¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–åŠ è½½å·²æœ‰æ¨¡å‹ã€‚"

            # åŠ è½½é¢„æµ‹æ•°æ®
            df = self.data_processor.load_data(data_path)

            # é¢„å¤„ç†
            df = self.data_processor.preprocess_data(df, handle_missing='mean')

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡åˆ—ï¼ˆçœŸå®å€¼ï¼‰
            has_true_values = False
            true_values = None
            if self.data_processor.target_name in df.columns:
                has_true_values = True
                true_values = df[self.data_processor.target_name].copy()
                X = df.drop(columns=[self.data_processor.target_name])
            else:
                X = df

            # é¢„æµ‹
            predictions = self.ml_manager.predict(X)

            # åˆ›å»ºç»“æœDataFrame
            result_df = X.copy()
            if has_true_values:
                result_df['çœŸå®å€¼'] = true_values
            result_df['é¢„æµ‹å€¼'] = predictions

            # ä¿å­˜é¢„æµ‹ç»“æœ
            output_path = os.path.join(
                self.config['report']['output_dir'],
                'predictions.csv'
            )
            result_df.to_csv(output_path, index=False)

            # å¦‚æœæœ‰çœŸå®å€¼ï¼Œè®¡ç®—æ€§èƒ½æŒ‡æ ‡
            result = f"""
é¢„æµ‹å®Œæˆï¼

ä½¿ç”¨æ¨¡å‹: {self.ml_manager.best_model_name}
é¢„æµ‹æ•°é‡: {len(predictions)}
é¢„æµ‹èŒƒå›´: [{predictions.min():.4f}, {predictions.max():.4f}]
å¹³å‡å€¼: {predictions.mean():.4f}
"""

            if has_true_values:
                from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
                import numpy as np

                mse = mean_squared_error(true_values, predictions)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(true_values, predictions)
                r2 = r2_score(true_values, predictions)

                result += f"""
**é¢„æµ‹æ€§èƒ½** (ä¸çœŸå®å€¼å¯¹æ¯”):
- RÂ² Score: {r2:.4f}
- RMSE: {rmse:.4f}
- MAE: {mae:.4f}
"""

            result += f"""
ç»“æœå·²ä¿å­˜è‡³: {output_path}
"""
            return result.strip()

        except Exception as e:
            logger.error(f"Prediction failed: {str(e)}")
            return f"é¢„æµ‹å¤±è´¥: {str(e)}"

    def _handle_analysis(self, instruction: str, data_path: str) -> str:
        """å¤„ç†æ•°æ®åˆ†æä»»åŠ¡"""
        logger.info("Handling analysis task...")

        try:
            # åŠ è½½æ•°æ®
            df = self.data_processor.load_data(data_path)

            # è·å–æ•°æ®æ‘˜è¦
            summary = self.data_processor.get_data_summary(df)

            # æ£€æµ‹æ•°æ®é—®é¢˜
            issues = self.data_processor.detect_data_issues(df)

            # æ ¼å¼åŒ–è¾“å‡º
            result = f"""
æ•°æ®åˆ†æç»“æœï¼š

ğŸ“Š åŸºæœ¬ä¿¡æ¯:
- æ•°æ®è§„æ¨¡: {summary['shape'][0]} è¡Œ Ã— {summary['shape'][1]} åˆ—
- å†…å­˜å ç”¨: {summary['memory_usage']:.2f} MB

ğŸ” æ•°æ®è´¨é‡:
- ç¼ºå¤±å€¼: {sum(summary['missing_values'].values())} ä¸ª
- é‡å¤è¡Œ: {issues['duplicates']} æ¡
- å¼‚å¸¸å€¼æ£€æµ‹: {len(issues['outliers'])} ä¸ªç‰¹å¾åŒ…å«å¼‚å¸¸å€¼

ğŸ“ˆ æ•°æ®å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚
"""
            self.current_data = df
            return result.strip()

        except Exception as e:
            logger.error(f"Analysis failed: {str(e)}")
            return f"åˆ†æå¤±è´¥: {str(e)}"

    def _handle_report_generation(self, instruction: str) -> str:
        """å¤„ç†æŠ¥å‘Šç”Ÿæˆä»»åŠ¡"""
        logger.info("Handling report generation task...")

        try:
            if self.model_results is None:
                return "é”™è¯¯ï¼šè¯·å…ˆè®­ç»ƒæ¨¡å‹ã€‚"

            # è·å–æ•°æ®æ‘˜è¦
            data_summary = self.data_processor.get_data_summary(self.current_data)

            # æ£€æµ‹æ•°æ®é—®é¢˜
            data_issues = self.data_processor.detect_data_issues(self.current_data)

            # å°è¯•åŠ è½½é¢„æµ‹ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            predictions_df = None
            predictions_path = os.path.join(
                self.config['report']['output_dir'],
                'predictions.csv'
            )
            if os.path.exists(predictions_path):
                try:
                    predictions_df = pd.read_csv(predictions_path)
                    logger.info(f"Loaded predictions from {predictions_path}")
                except Exception as e:
                    logger.warning(f"Failed to load predictions: {str(e)}")

            # ç”ŸæˆæŠ¥å‘Š
            report_path = self.report_generator.generate_report(
                data_summary=data_summary,
                model_results=self.model_results,
                predictions=predictions_df,  # ä¼ é€’é¢„æµ‹ç»“æœ
                feature_importance=self.feature_importance,
                data_issues=data_issues
            )

            # ä¿å­˜å¯è§†åŒ–å›¾è¡¨
            plots = self.report_generator.save_visualizations(
                self.model_results,
                self.feature_importance
            )

            result = f"""
æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼

ğŸ“„ MarkdownæŠ¥å‘Š: {report_path}
ğŸ“Š å¯è§†åŒ–å›¾è¡¨: {len(plots)} ä¸ª

æŠ¥å‘ŠåŒ…å«:
âœ… æ•°æ®åˆ†ææ‘˜è¦
âœ… æ¨¡å‹æ€§èƒ½å¯¹æ¯”
âœ… ç‰¹å¾é‡è¦æ€§åˆ†æ
âœ… é¢„æµ‹ç»“æœåˆ†æ {'(å·²åŒ…å«)' if predictions_df is not None else '(æœªåŒ…å«)'}
âœ… æ”¹è¿›å»ºè®®

è¯·æŸ¥çœ‹æŠ¥å‘Šæ–‡ä»¶è·å–è¯¦ç»†ä¿¡æ¯ã€‚
"""
            return result.strip()

        except Exception as e:
            logger.error(f"Report generation failed: {str(e)}")
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"

    def _handle_general_query(self, instruction: str) -> str:
        """å¤„ç†é€šç”¨æŸ¥è¯¢ï¼ˆä½¿ç”¨LLMï¼‰"""
        logger.info("Handling general query with LLM...")

        # åˆå§‹åŒ–LLMï¼ˆå¦‚æœè¿˜æœªåˆå§‹åŒ–ï¼‰
        self.initialize_llm()

        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªç ”ç£¨é€Ÿåº¦é¢„æµ‹é¢†åŸŸçš„AIåŠ©æ‰‹ã€‚ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·ï¼š
1. è®­ç»ƒé¢„æµ‹æ¨¡å‹
2. è¿›è¡Œæ•°æ®é¢„æµ‹
3. åˆ†ææ•°æ®è´¨é‡
4. ç”Ÿæˆåˆ†ææŠ¥å‘Š

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›ä¸“ä¸šçš„å»ºè®®ã€‚"""

        # ä½¿ç”¨LLMå›ç­”
        response, self.conversation_history = self.llm.chat(
            instruction,
            history=self.conversation_history,
            system=system_prompt
        )

        return response

    def execute_pipeline(self, data_path: str, target_column: Optional[str] = None) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„é¢„æµ‹æµç¨‹

        Args:
            data_path: æ•°æ®è·¯å¾„
            target_column: ç›®æ ‡åˆ—å

        Returns:
            æ‰§è¡Œç»“æœ
        """
        logger.info("Executing full prediction pipeline...")

        results = []

        # 1. æ•°æ®åˆ†æ
        results.append("=" * 50)
        results.append("æ­¥éª¤ 1: æ•°æ®åˆ†æ")
        results.append("=" * 50)
        analysis_result = self._handle_analysis("åˆ†ææ•°æ®", data_path)
        results.append(analysis_result)

        # 2. æ¨¡å‹è®­ç»ƒ
        results.append("\n" + "=" * 50)
        results.append("æ­¥éª¤ 2: æ¨¡å‹è®­ç»ƒ")
        results.append("=" * 50)
        training_result = self._handle_training("è®­ç»ƒæ¨¡å‹", data_path)
        results.append(training_result)

        # 3. ç”ŸæˆæŠ¥å‘Š
        results.append("\n" + "=" * 50)
        results.append("æ­¥éª¤ 3: ç”ŸæˆæŠ¥å‘Š")
        results.append("=" * 50)
        report_result = self._handle_report_generation("ç”ŸæˆæŠ¥å‘Š")
        results.append(report_result)

        results.append("\n" + "=" * 50)
        results.append("âœ… å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
        results.append("=" * 50)

        return "\n".join(results)
